{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Example for Airflow\n",
    "\n",
    "This is a nice example of how you might utilize Twitter as part of a workflow.  Saving this will automatically generate the .py file and make it a\n",
    "\n",
    " Adopted from script written By: Ekhtiar Syed\n",
    " Last Update: 8th April 2016\n",
    " Caveat: This Dag will not run because of missing scripts.\n",
    " The purpose of this is to give you a sample of a real world example DAG!\n",
    " \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    " http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import airflow\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'Ekhtiar',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2017, 1, 1),\n",
    "    'email': ['airflow@airflow.com'],\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    # 'queue': 'bash_queue',\n",
    "    # 'pool': 'backfill',\n",
    "    # 'priority_weight': 10,\n",
    "    # 'end_date': datetime(2016, 1, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create a few placeholder scripts. In practice these would be different python\n",
    "# script files, which are imported in this section with absolute or relative imports\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def fetchtweets():\n",
    "    return None\n",
    "\n",
    "\n",
    "def cleantweets():\n",
    "    return None\n",
    "\n",
    "\n",
    "def analyzetweets():\n",
    "    return None\n",
    "\n",
    "\n",
    "def transfertodb():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-02-18 16:04:46,872] {__init__.py:36} INFO - Using executor SequentialExecutor\n"
     ]
    }
   ],
   "source": [
    "dag = DAG(\n",
    "    'example_twitter_dag', default_args=default_args,\n",
    "    schedule_interval=\"@daily\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# This task should call Twitter API and retrieve tweets from yesterday from and to\n",
    "# for the four twitter users (Twitter_A,..,Twitter_D) There should be eight csv\n",
    "# output files generated by this task and naming convention\n",
    "# is direction(from or to)_twitterHandle_date.csv\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "fetch_tweets = PythonOperator(\n",
    "    task_id='fetch_tweets',\n",
    "    python_callable=fetchtweets,\n",
    "    dag=dag)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Clean the eight files. In this step you can get rid of or cherry pick columns\n",
    "# and different parts of the text\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "clean_tweets = PythonOperator(\n",
    "    task_id='clean_tweets',\n",
    "    python_callable=cleantweets,\n",
    "    dag=dag)\n",
    "\n",
    "clean_tweets.set_upstream(fetch_tweets)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# In this section you can use a script to analyze the twitter data. Could simply\n",
    "# be a sentiment analysis through algorithms like bag of words or something more\n",
    "# complicated. You can also take a look at Web Services to do such tasks\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "analyze_tweets = PythonOperator(\n",
    "    task_id='analyze_tweets',\n",
    "    python_callable=analyzetweets,\n",
    "    dag=dag)\n",
    "\n",
    "analyze_tweets.set_upstream(clean_tweets)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Although this is the last task, we need to declare it before the next tasks as we\n",
    "# will use set_downstream This task will extract summary from Hive data and store\n",
    "# it to MySQL\n",
    "# --------------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
